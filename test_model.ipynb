{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e00ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# testset = np.load(\"../masif_features/testset.npy\", allow_pickle=True)\n",
    "# valset = np.load(\"../masif_features/valset.npy\", allow_pickle=True)\n",
    "# trainset = np.load(\"../masif_features/trainset.npy\", allow_pickle=True)\n",
    "# testset.shape, valset.shape, trainset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b17040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter(trainset[:, -1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9056b-4bce-458d-b1b1-d25c88fafdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/ppi_fork/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNN_graph_only Loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from metrics import *\n",
    "from data_prepare import testloader\n",
    "from models import (\n",
    "    GCNN,\n",
    "    GCNN_desc_pool,\n",
    "    GCNN_geom_transformer,\n",
    "    AttGNN_baseline,\n",
    "    GCNN_geom_transformer_without_descriptors,\n",
    "    GCNN_geom_transformer_without_graph\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.cuda(\"cpu\")\n",
    "\n",
    "# model = GCNN()\n",
    "# model.load_state_dict(torch.load(\"../masif_features/GCN_baseline.pth\"))\n",
    "\n",
    "# model = GCNN_desc_pool()\n",
    "# model.load_state_dict(torch.load(\"../masif_features/GCN_pool.pth\"))\n",
    "\n",
    "# model = GCNN_geom_transformer(num_layers=2, dropout=0.1, num_features_pro=1024, output_dim=128, descriptor_dim=80, transformer_dim=128, nhead=8, dim_feedforward=256)\n",
    "# model.load_state_dict(torch.load(\"../masif_features/GCN_geom_01.pth\"))\n",
    "\n",
    "# model = AttGNN_baseline(dropout=0.1, heads=1)\n",
    "# model.load_state_dict(torch.load(\"../masif_features/AttGNN_baseline_l1.pth\"))\n",
    "\n",
    "# model = GCNN_geom_transformer(num_layers=3, dropout=0.1, num_features_pro=1024, output_dim=128, descriptor_dim=80, transformer_dim=128, nhead=8, dim_feedforward=256)\n",
    "# model.load_state_dict(torch.load(\"../masif_features/GCN_geom_01_l3.pth\"))\n",
    "\n",
    "model = GCNN_geom_transformer_without_descriptors(num_layers=2, dropout=0.3, num_features_pro=1024, output_dim=128, descriptor_dim=80, transformer_dim=128, nhead=8, dim_feedforward=256)\n",
    "model.load_state_dict(torch.load(\"../masif_features/GCNN_geom_transformer_without_descriptors_l2.pth\"))\n",
    "\n",
    "# model = GCNN_geom_transformer_without_graph(num_layers=2, dropout=0.3, num_features_pro=1024, output_dim=128, descriptor_dim=80, transformer_dim=128, nhead=8, dim_feedforward=256)\n",
    "# model.load_state_dict(torch.load(\"../masif_features/GCNN_geom_transformer_without_graph_l2.pth\"))\n",
    "\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe01962a-d8bb-46cf-82af-bf74a2f2ad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7680 [00:00<?, ?it/s]/workspace/ppi_fork/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      " 56%|█████▌    | 4318/7680 [06:05<03:44, 14.98it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "predictions = torch.Tensor()\n",
    "labels = torch.Tensor()\n",
    "with torch.no_grad():\n",
    "    for prot_1, prot_2, label, mas1_straight, mas1_flipped, mas2_straight, mas2_flipped, mas1_straight_lengths, mas1_flipped_lengths, mas2_straight_lengths, mas2_flipped_lengths in tqdm(testloader):\n",
    "      prot_1 = prot_1.to(device)\n",
    "      prot_2 = prot_2.to(device)\n",
    "      mas1_straight = mas1_straight.to(device)\n",
    "      mas1_flipped = mas1_flipped.to(device)\n",
    "      mas2_straight = mas2_straight.to(device)\n",
    "      mas2_flipped = mas2_flipped.to(device)\n",
    "      output = model(prot_1, prot_2, mas1_straight, mas1_flipped, mas2_straight, mas2_flipped, mas1_straight_lengths, mas1_flipped_lengths, mas2_straight_lengths, mas2_flipped_lengths)\n",
    "      predictions = torch.cat((predictions, output.cpu()), 0)\n",
    "      labels = torch.cat((labels, label.view(-1,1).cpu()), 0)\n",
    "labels = labels.numpy().flatten()\n",
    "predictions = predictions.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ed785-cc9a-4ea2-a508-34057c01e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse : 38.93427658081055\n",
      "Accuracy : 96.6015625\n",
      "precision: 0.9592185592185593\n",
      "Sensititvity :0.9766285430134262\n",
      "specificity : 0.9543466375068343\n",
      "f-score : 0.9678452630282125\n",
      "MCC : 0.9319861396509743\n",
      "AUROC: 0.9943931259429072\n",
      "AUPRC: 0.9949231545899945\n"
     ]
    }
   ],
   "source": [
    "mse = get_mse(labels, predictions)\n",
    "acc = get_accuracy(labels, predictions, 0.5)\n",
    "prec = precision(labels, predictions, 0.5)\n",
    "sensitivity = sensitivity(labels, predictions,  0.5)\n",
    "specificity = specificity(labels, predictions, 0.5)\n",
    "f1 = f_score(labels, predictions, 0.5)\n",
    "mcc = mcc(labels, predictions,  0.5)\n",
    "auroc = auroc(labels, predictions)\n",
    "auprc = auprc(labels, predictions)\n",
    "\n",
    "\n",
    "print(f'mse : {mse}')\n",
    "print(f'Accuracy : {acc}')\n",
    "print(f'precision: {prec}')\n",
    "print(f'Sensititvity :{sensitivity}')\n",
    "print(f'specificity : {specificity}')\n",
    "print(f'f-score : {f1}')\n",
    "print(f'MCC : {mcc}')\n",
    "print(f'AUROC: {auroc}')\n",
    "print(f'AUPRC: {auprc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b2bc3-b266-4900-a686-0aae9934c822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
